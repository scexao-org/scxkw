#!/bin/env python
'''
Consolidation of framelist files found in vgen2

Usage:
    scxkw-vamp-summary <DATE> [--fits] [-P]
    scxkw-vamp-summary -f <FOLDER> [--fits] [-P]

Options:
    --fits  Use fits files instead of fitsframes files
    -P      Use a 10-parallel pool (possibly, this is quite CPU bound.)
'''
import typing as typ

from pathlib import Path

import docopt

# FIXME start logger.

from scxkw.config import GEN2PATH_NODELETE
from scxkw.tools import file_tools
from scxkw.tools.framelist_file_obj import FrameListFitsFileObj
from scxkw.tools.fits_file_obj import FitsFileObj

def write_func(fobjs_framelist, fobjs_fits_dict):
    fitsobj = file_tools.consolidate_framelist_to_fits(fobjs_framelist, fobjs_fits_dict)
    fitsobj.write_to_disk(try_flush_ram=True)
    # If the write is successful, we should get rid of the fitsframes, otherwise
    # We might consolidate it a second time...

    ### WARNING! the txt is shared!
    fobjs_framelist.disown_txt_file()
    fobjs_framelist.delete_from_disk()

if __name__ == "__main__":

    args = docopt.docopt(__doc__)

    FOLDER = args['<FOLDER>']
    DATE = args['<DATE>']
    PARALLEL = args['-P']

    if FOLDER is None:
        dateFolderPath = Path(GEN2PATH_NODELETE) / DATE
    else:
        dateFolderPath = Path(FOLDER)
        DATE = dateFolderPath.name

    assert (dateFolderPath.is_absolute() and dateFolderPath.is_dir())

    fobjs_framelists = file_tools.make_fileobjs_from_globs(
                       [str(dateFolderPath) + '/vgen2/*.fitsframes'], [],
                       type_to_use=FrameListFitsFileObj)
    fobjs_framelists.sort(key=lambda fobj: fobj.get_start_unixtime_secs())

    set_needed_fits: typ.Set[str] = set()
    for fobj in fobjs_framelists:
        fobj._ensure_data_loaded()
        set_needed_fits.update(set(fobj.data[:,0]))

    # Save time if we don't need to load all the set (little amount of .fitsframes remaining)
    fobjs_fits = [FitsFileObj(fullname=fname) for fname in set_needed_fits]
    fobjs_fits_dict = {str(fo.full_filepath): fo for fo in fobjs_fits}

    import multiprocessing # Using multiprocessing is a bit faster, and also keeps the RAM in check
    # But careful: files may appear in timely disorder

    for slice_idx in range(len(fobjs_framelists) // 10 + 1):
        ps = []
        for fobjs_framelist in fobjs_framelists[10*slice_idx:10*slice_idx+10]:

            ps += [multiprocessing.Process(target=write_func, args=(fobjs_framelist, fobjs_fits_dict))]
            ps[-1].start()
    
        for p in ps:
            p.join()